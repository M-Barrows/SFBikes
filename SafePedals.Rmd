---
title: "Project Proposal"
author: Michael Barrows
date: "`r Sys.Date()`"
output: 
  html_notebook:
    toc: true
    toc_float: true
    theme: journal
---

## Introduction

### Statement of Purpose 

As populations steadily rise, citizens in bustling urban centers like San Francisco face increased difficulty regarding safe and efficient travel. Cars can be relatively efficient (higher speed) and relatively safe but often fall victim to variable traffic patters. Conversely, walking is much safer but also much slower than driving in a car. In this light, many people are turning to bicycles as their preferred mode of transportation as they offer increased route flexibility over cars and increased travel speed when compared to walking. The Ford Go-Bikes in San Francisco offer citizens an affordable and flexible way to make this transition. 
  
Unfortunately, cities harbor more transportation perils than simply busy streets. These may include poor road conditions, bike scarcity, dangerous weather conditions, and more. In this report, crime events were tracked alongside bike trips in an attempt to identify areas and bike stations within San Francisco that might be more dangerous than others. With this knowledge, users of the Go-Bikes  will be able to identify the safest route route through the city. 

In addition to comparing the spacial distribution of bike routes and crime events to benefit bikers, the distribution of permitted food trucks will also be observed to benefit food truck owners as well as bikers. The purpose of this comparison is two-fold. First, it will allow food truck owners to more strategically plan their truck placement to drum up business. Second, it can aid regular users of Go-Bikes in optimizing their route to pass by their favorite food truck on their way from point A to point B. 

In concert with each other, these three datasets will greatly increase the trip quality of Go-Bike users as well as bolster local business.

### Planned Analyses

In order to achieve the propositions above, several techniques will be employed. 

* Descriptive statistics to gain basic insight
* Interactive geospatial mapping for data visualization
* Historical trend analysis and forecasting
* _Others_
  
## Set-up

### Load Required Packages

Before we begin working with any data, we need to install some key packages that will make future tasks easier. These packages are:

| Package     | Function                    |
|------------:|:---------------------------:|
| data.table  | reading data from the web   |
| lubridate   | converting strings to dates |
| tidyr       | easy data format cleaning   |
| dplyr       | data manipulation           |
| DT          | writing data tables to HTML |
| knitr       | compile RMarkdown into HTML |
| ggplot2     | powerful plotting function  |
| plotly      | create interactive figures  |
| leaflet     | interactive geospatial maps |


The following code chunk checks your personal environment for the necessary packages, installs them if they don't exist, and then loads all of them into the environment for use.

```{r install and load required packages, message = FALSE, warning = FALSE}
#Remove all objects in Environment for a clean start
rm(list = ls())

#Install necessary packages only if they aren't already installed
list.of.packages <- c("data.table","lubridate","tidyr","dplyr","DT","knitr","ggplot2","plotly","leaflet")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
invisible(if (length(new.packages)) install.packages(new.packages))

#load the required packages
invisible(require(data.table))
invisible(require(lubridate))
invisible(require(tidyr))
invisible(require(dplyr))
invisible(require(DT))
invisible(require(knitr))
invisible(require(ggplot2))
invisible(require(plotly))
invisible(require(leaflet))
```

### Import Raw Data

We will be utilizing three datasets for our analysis: 

1. [Bay Area Bike Share](https://www.fordgobike.com/system-data): Each row contains information about a bike trip

2. [SF Police Incidents](https://data.sfgov.org/Public-Safety/-Change-Notice-Police-Department-Incidents/tmnf-yvry): Each row contains information about a crime incident

3. [Food Truck Locations](https://data.sfgov.org/Economy-and-Community/Mobile-Food-Schedule/jjew-r69b): Each row contains information about one food truck at a particular time.

All three of these datasets are open and available as of writing of this document. Each dataset was downloaded and stored to their own variables using the code below. In the next step, the data were cleaned and reformatted. After which a full codebook is provided for each dataset.

```{r load all data, message = F, warning = F,results=F}
bikes <- fread("https://s3.amazonaws.com/fordgobike-data/2017-fordgobike-tripdata.csv", data.table = F, na.strings = c(""," ","NA","N/A"))
crime <- fread("https://data.sfgov.org/api/views/tmnf-yvry/rows.csv", data.table = F, na.strings = c(""," ","NA","N/A"))
truck <- fread("https://data.sfgov.org/api/views/jjew-r69b/rows.csv", data.table = F, na.strings = c(""," ","NA","N/A"))
```

### Reformat

After gathering our data, there is quite a bit of reformatting that needs to happen before we can perform any computation or other analyses. Much of this reformatting is attribute reclassification from strings to something more appropriate (int, date, etc.).

#### Bikes 

Upon initial download, the `bikes` data is in the format below: 
```{r glimpse bike data}
glimpse(bikes)
```

While the data are tidy, in that each row represents a single trip observation, many attributes need to be reformatted to be consistent with the data they hold. For example, the time attributes need to be converted from `character` values to `date-time` values. Similarly, the latitude and longitude values were converted from `string` to `double`.  The `*_id` attributes were left as strings to avoid improperly using them as integers and performing math calculations on them. The code below will reformat 10 of the `r length(names(bikes))` attributes.

```{r reformat bike attributes}
# reformat duration_sec and member_birth_year to integer
bikes$duration_sec <- as.integer(bikes$duration_sec)
bikes$member_birth_year <- as.integer(bikes$member_birth_year)

# reformat start and end time to date
bikes$start_time <- ymd_hms(bikes$start_time)
bikes$end_time <- ymd_hms(bikes$end_time)

# reformat station latitude and longitude values to double
bikes$start_station_latitude <- as.double(bikes$start_station_latitude)
bikes$start_station_longitude <- as.double(bikes$start_station_longitude)
bikes$end_station_latitude <- as.double(bikes$end_station_latitude)
bikes$end_station_longitude <- as.double(bikes$end_station_longitude)

# reformat user_type and member_gender as factors
bikes$user_type <- as.factor(bikes$user_type)
bikes$member_gender <- as.factor(bikes$member_gender)
```

#### Crime

The `crime` data as compiled from the source is as follows:  
```{r glimps crime data}
glimpse(crime)
```

Like the `bike` data, date-time attributes within the `crime` dataset need to be converted from a `character` format. Additionally, the column names `X` and `Y` are converted to `Longitude` and `Latitude` respectively for readability. Like the `id` values in the `bike` data, the `IncidntNum` values were converted to characters to avoid accidental math calculations. Lastly, the `Category` attribute was converted to a `factor` type.

```{r reformat crime attributes}
# Reformat Category as a factor
crime$Category <- as.factor(crime$Category)
# Combine Date and Time columns, remove the originals
crime <- crime %>% unite(Date_Time,Date,Time,sep = " ",remove = T)
# Reformat Date_Time appropriately
crime$Date_Time <- mdy_hm(crime$Date_Time)
# rename X and Y to Longitude and Latitude respectively
names(crime)[which(names(crime) == "X")] <- "Longitude"
names(crime)[which(names(crime) == "Y")] <- "Latitude"
# format incident number as character
crime$IncidntNum <- as.character(crime$IncidntNum)

```


#### Food Trucks

The last dataset that is used in this analysis is the `truck` dataset. In it's raw form, it is organized as follows: 
```{r glimpse truck data}
glimpse(truck)
```

Like the previous two datasets, we reformat the `truck` data so that the data formats are representative of values they hold. 

```{r reformat truck attributes}
# Reformat ColdTruck as factor
truck$ColdTruck <- as.factor(truck$ColdTruck)

# Reformat Addr_Date_Create and Addr_date_Modified as Date
truck$Addr_Date_Create <- mdy_hms(truck$Addr_Date_Create)
truck$Addr_Date_Modified <- mdy_hms(truck$Addr_Date_Modified)

# Reformat start24 and end24 as time
truck$start24 <- hm(truck$start24)
truck$end24 <- hm(truck$end24)
```


### Pruning

While the age of big-data has arrived, it is often preferable to trim a dataset down to its smallest useful form. In the following two sections the datasets were trimmed down in both dimensions (rows and columns) to make them as simple as possible while still providing useful insight. 

#### Columns

Many attributes in these datasets might have been helpful for clerical reference or when converting values like day of the week from a number to words. However, for our use case, they are unnecessary. The following variables were removed: 

**Crime**

* `DayofWeek`
* `Address`
* `PdDistrict`
* `PdId`
* `Location`

**Truck**

* `starttime`
* `endtime`
* `PermitLocation`
* `locationdesc`
* `optionaltext`
* `locationid`
* `scheduleid`
* `scheduleid`
* `CNN`
* `block`
* `lot`
* `ColdTruck`
* `Applicant`

```{r prune columns}
# remove three attributes from crime dataset
crime <- crime %>% select(-c(DayOfWeek, Address,PdDistrict, PdId, Location))

# select columns to keep from truck dataset
truck <- truck %>% select(c(permit, Latitude, Longitude, DayOrder, DayOfWeekStr, start24, end24, Addr_Date_Create, Addr_Date_Modified))
```

#### Rows

In order to make useful comparisons across datasets, each observation needed to be made within a common date range. To determine this date range, we found the latest starting date and the earliest ending date from all three datasets. Then, we applied a filter to each dataset to only include observations between those two dates.

```{r prune rows}
# Find the latest starting date
latest_start <- max(c(min(bikes$start_time, na.rm = T),min(crime$Date_Time, na.rm = T),min(truck$Addr_Date_Create, na.rm = T)))
# Find the earliest ending date
earliest_end <- min(c(max(bikes$end_time, na.rm = T),max(crime$Date_Time, na.rm = T),max(truck$Addr_Date_Modified,na.rm = T)))
# Filter all datasets to the same date range
bikes <- bikes %>% filter(start_time >= latest_start & end_time <= earliest_end)
crime <- crime %>% filter(Date_Time >= latest_start & Date_Time <= earliest_end)
truck <- truck %>% filter(Addr_Date_Create >= latest_start & Addr_Date_Modified <= earliest_end)
# All observations now in the same date range for increased robustness
```

## Codebooks {.tabset .tabset-fade}

The "Codebooks" are concise descriptions of each dataset collected after it has been cleaned from the preceding steps. They include a download link to the original source file, a short description of the data as well as a list of attributes (their name, type and a description), and an exploitable version of the data. All null/missing values (in both the original and cleaned data) have been represented as "NA". The only attributes that contain NA values are the `member_birth_year` and `member_gender` attributes in the bike data. This happens for every "Customer" entry as they only track this information for members.

### Bikes

**Source**: [Download from Ford Go-Bikes](https://s3.amazonaws.com/fordgobike-data/2017-fordgobike-tripdata.csv)

**Description**: This dataset includes data on bike trips made on Ford Go-Bikes around the city of San Francisco from `r min(bikes$start_time)` to `r max(bikes$end_time)`. It contains `r nrow(bikes)` observations and `r ncol(bikes)` attributes.

**Attributes**

|Attribute            |Format                |Description|
|---------------------|----------------------|-----------|
|`r names(bikes)[1]`  |`r class(bikes[,1])`  | Total time of trip (s)|
|`r names(bikes)[2]`  |`r class(bikes[,2])`  | Starting time of trip (YMD HMS)|
|`r names(bikes)[3]`  |`r class(bikes[,3])`  | Ending time of trip (YMD HMS)|
|`r names(bikes)[4]`  |`r class(bikes[,4])`  | Starting station number|
|`r names(bikes)[5]`  |`r class(bikes[,5])`  | Starting station name|
|`r names(bikes)[6]`  |`r class(bikes[,6])`  | Starting station latitude|
|`r names(bikes)[7]`  |`r class(bikes[,7])`  | Starting station longitude|
|`r names(bikes)[8]`  |`r class(bikes[,8])`  | Ending station number|
|`r names(bikes)[9]`  |`r class(bikes[,9])`  | Ending station name|
|`r names(bikes)[10]` |`r class(bikes[,10])` | Ending station latitude|
|`r names(bikes)[11]` |`r class(bikes[,11])` | Ending station longitude|
|`r names(bikes)[12]` |`r class(bikes[,12])` | Bike number|
|`r names(bikes)[13]` |`r class(bikes[,13])` | User Type ("Customer" or "Subscriber")|
|`r names(bikes)[14]` |`r class(bikes[,14])` | Birth year of Subscriber |
|`r names(bikes)[15]` |`r class(bikes[,15])` | Gender of Subscriber ("Male" or "Female")|

**Dataset**:

```{r view bike data, message = F, warning = F}
as_tibble(bikes)
```


### Crime

**Source**: [Download from data.sf.gov](https://data.sfgov.org/api/views/tmnf-yvry/rows.csv?accessType=DOWNLOAD)

**Description**: This dataset includes information about crime incidents in the San Francisco area from `r min(crime$Date_Time)` to `r max(crime$Date_Time)`. It contains `r nrow(crime)` observations and `r ncol(crime)`attributes.

**Attributes**:

|Attribute          |Format               |Description|
|-------------------|---------------------|-----------|
|`r names(crime)[1]`|`r class(crime[,1])` | Unique incident number |
|`r names(crime)[2]`|`r class(crime[,2])` | Type of incident (`r nrow(distinct(crime,Category))` unique values) |
|`r names(crime)[3]`|`r class(crime[,3])` | Longer incident description |
|`r names(crime)[4]`|`r class(crime[,4])` | Date and time of incident (YMD HMS) |
|`r names(crime)[5]`|`r class(crime[,5])` | Incident resolution (if any) |
|`r names(crime)[6]`|`r class(crime[,6])` | Incident longitude |
|`r names(crime)[7]`|`r class(crime[,7])` | Incident latitude |

**Dataset**:

```{r view crime data, warning = F, message = F}
as_tibble(crime)
```


### Trucks

**Source**: [Download from data.sf.gov](https://data.sfgov.org/api/views/jjew-r69b/rows.csv?accessType=DOWNLOAD)

**Description**: This dataset includes information about food truck locations and schedules around the San Francisco area with permit approvals from `r min(truck$Addr_Date_Create)` to `r max(truck$Addr_Date_Create)`. It has `r nrow(truck)` observations and `r ncol(truck)` attributes. 

**Attributes**: 

|Attribute            |Format                |Description|
|---------------------|----------------------|-----------|
|`r names(truck)[1]`  |`r class(truck[,1])`  | Permit number |
|`r names(truck)[2]`  |`r class(truck[,2])`  | Latitude of permit location|
|`r names(truck)[3]`  |`r class(truck[,3])`  | Longitude of permit location|
|`r names(truck)[4]`  |`r class(truck[,4])`  | Day of week as integer (1=Monday : 7=Sunday)|
|`r names(truck)[5]`  |`r class(truck[,5])`  | Day of week in word format|
|`r names(truck)[6]`  |`r class(truck[,6])`  | Start time of food truck schedule in 24-hour time |
|`r names(truck)[7]`  |`r class(truck[,7])`  | End time of food truck schedule in 24-hour time|
|`r names(truck)[8]`  |`r class(truck[,8])`  | Date permit was created|
|`r names(truck)[9]`  |`r class(truck[,9])`  | Date permit was updated|

**Dataset**: 

```{r view truck data, message = F, warning = F}
as_tibble(truck)
```


## Initial Exploration

Much of the goal of this project is to provide a platform for self discovery of others through the use of interactive maps and at-a-glance dashboards. Since this functionality is largely incomplete at the moment, a few key summary statistics and figures have been identified to get a basic understanding of the events within the data.

### Bikes

We first start by calculating some basic ridership statistics from the bike dataset. The code for doing so is shown below with a summary table below that. 

```{r calculate specific values in bike data}
# Find average ride length in minutes for All riders, Members, and non-members
mean_ride_all <- round(mean(bikes$duration_sec, na.rm = T)/60,0)

mean_ride_members <- round(mean(filter(bikes, user_type == "Subscriber")$duration_sec, na.rm = T)/60,0)
mean_ride_customers <- round(mean(filter(bikes, user_type == "Customer")$duration_sec, na.rm = T)/60,0)

# Determine the Male:Female split of members
bikes_member <- filter(bikes,!is.na(member_gender))
perc_male <- round(sum(bikes_member$member_gender == "Male")/sum(bikes_member$member_gender == "Male" | bikes_member$member_gender == "Female")*100,2)
perc_female <- round(sum(bikes_member$member_gender == "Female")/sum(bikes_member$member_gender == "Male" | bikes_member$member_gender == "Female")*100,2)

# Determine Popular Stations
popular_start <- unique(bikes$start_station_name)[which.max(tabulate(match(bikes$start_station_name, unique(bikes$start_station_name))))]
popular_end <- unique(bikes$end_station_name)[which.max(tabulate(match(bikes$end_station_name, unique(bikes$end_station_name))))]
```


|Metric                                   | Value                                    |
|----------------------------------------:|:----------------------------------------:|
|Average Ride Duration (All)[minutes]| `r mean_ride_all` |
|Average Ride Duration (Members)[minutes] | `r mean_ride_members` |
|Average Ride Duration (Non-Members)[minutes] | `r mean_ride_customers` |
|Percent Members (Male) | `r perc_male`% |
|Percent Members (Female) | `r perc_female`% |
|Most popular start station | `r popular_start` |
|Most popular destination station |`r popular_end` |

With some of the notable statistics determined, the next step was to create some basic plots. The first of which was a simple scatter plot of ride duration against date.

```{r plot ride length over time}
ggplot(bikes, aes(x = start_time, y = duration_sec/60)) + 
  geom_point(aes(color = user_type)) +
  labs(title = "Ride length over time for customers and subscribers",
       x = "Date",
       y = "Ride duration (minutes)")
```

When viewing this figure, it is worth noting that the number of minutes in a day is 1,440. Based on the figure, it appears that the rides end after 24 hours whether the bike has been returned or not. This will potentially lead to data inconsistencies. The figure also makes it easy to see that a large number of trips are less than 500 minutes (8.3hrs). We further confirm that with the following figure.
```{r plot distribution of ride length, warning = F}
ggplot(bikes, aes(duration_sec/60)) + 
  geom_density() + 
  labs(title = "Distribution curve of ride duration",
       x = "Ride duration (minutes)")
```

If we restrict the x axis of the previous figure a little, we can see that the largest amount of riders actually rides for less than 40 minutes.
```{r trimmed ride length distribution plot, warning = F, message = F}
ggplot(bikes, aes(duration_sec / 60)) + 
  geom_density() +
  labs(title = "Distribution curve of ride duration",
       x = "Ride duration (minutes)") +
  scale_x_continuous(limits = c(0,60))
```

### Crime

When analyzing the crime data, there are three major metrics of importance: when, where, and what. Below we calculate (and summarize in a table) the month with the most crime incidents (*when*) and the most common type of crime (*what*).
```{r calculate specific values for crime data}
# Determine most popular crime
popular_crime <- unique(crime$Category)[which.max(tabulate(match(crime$Category, unique(crime$Category))))]

top_crime_month <- as.data.frame(crime %>% mutate( month = paste(year(Date_Time),month(Date_Time),sep = "-")) %>%  group_by(month) %>% summarise(n_incidents = n()) %>% arrange(desc(n_incidents)))[1,1]
```

|Metric                                   | Value                                    |
|----------------------------------------:|:----------------------------------------:|
|Most popular type of crime | `r popular_crime` |
|Highest crime month  | `r top_crime_month` |

To answer the *where* question, we plotted an interactive map of all crime events during the month with the most incidents identified above. 

```{r create map of crime during highest activity month, message = F, warning = F}
leaflet(data = crime %>% filter(Date_Time >= "2017-10-01" & Date_Time < "2017-11-01")) %>% addProviderTiles(providers$MtbMap) %>%
  addProviderTiles(providers$Stamen.TonerLines,
    options = providerTileOptions(opacity = 0.35)) %>%
  addProviderTiles(providers$Stamen.TonerLabels) %>%
  addMarkers(clusterOptions = markerClusterOptions(), label = ~Category, lat = ~Latitude, lng = ~Longitude)
```

### Trucks

Below is a map of all food truck permit locations. 
```{r map truck permit locations, message = F, warning = F}
leaflet(data = truck) %>%
          addProviderTiles(providers$MtbMap) %>% 
          addProviderTiles(providers$Stamen.TonerLines,
                           options = providerTileOptions(opacity = 0.35)) %>%
          addProviderTiles(providers$Stamen.TonerLabels) %>%
          addMarkers(clusterOptions = markerClusterOptions(), label = ~permit, lat = ~Latitude, lng = ~Longitude)
```


## Future Plans

In the future detailed, cohesive, and interactive maps will be used in a dashboard style presentation that will allow for user-derived insight into the safest routs for them or bikers in general. The following features are planned for the upcoming release: 

* Filter information by: 
    +   Date
    +   Crime Type
    +   Bike Station
    +   Location
    
* Informative Charts and tables (based on filters) for:
    +   Ridership over time
    +   Rider demographics
    +   Crime characteristics

In addition to the planned features, there are several features that may be developed depending on their ability to add clarity of understanding and available development time. These include

* Geographic spacial clustering analysis
* Integration of more datasets
    +   Demographic Information
    +   Road Quality
    +   Traffic Stops

## Summary

To recapitulate, the goal of this project is to increase the safety and convenience of bike riders as they traverse the busy streets of San Francisco. With the data already collected and cleaned, we hope to: 

* Derive some sense for where the safest areas to ride a Go-Bike are
* Identify ridership trends over time
* Provide spatial analysis of ridership for use by food truck owners

as well as other methods an techniques as time permits. 

In this first submission, great strides have been made to collect, clean, and organize three open datasets. Furthermore, some basic descriptive statistics and visualizations have been derived. In the next submission a deep dive into analysis will take place and valuable insights will be generated. 

